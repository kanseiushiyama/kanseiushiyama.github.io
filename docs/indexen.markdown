---
# Feel free to add content and custom Front Matter to this file.
# To modify the layout, see https://jekyllrb.com/docs/themes/#overriding-theme-defaults

layout: default
lang: en
title: Home
#home
---
# Kansei Ushiyama

Ph.D. student,<br>
[Mathematical Informatics 3rd Laboratory](http://www.sr3.t.u-tokyo.ac.jp/),<br>
Department of Mathemathical Informatics,<br>
Graduate School of Information Science and Technology,<br>
The University of Tokyo<br>
Email: ushiyama-kansei074 (at) g.ecc.u-tokyo.ac.jp

# Reserch Interests

- Numerical Analysis
- Continuous Optimization

# Preprints

1. **Deriving Optimal Rates of Continuous-time Accelerated First-order Methods via Performance Estimation Problems**<br>
   [[METR](https://www.keisu.t.u-tokyo.ac.jp/data/2024/METR24-02.pdf)]<br>
   K. Ushiyama, S. Sato, T. Matsuo, preprint.

# Refereed Journal Articles and Conference Proceedings

1. **Properties and practicability of convergence-guaranteed optimization methods derived from weak discrete gradients**<br>
   [[journal](https://doi.org/10.1007/s11075-024-01790-3)]<br>
   K. Ushiyama, S. Sato, T. Matsuo, Numer. Algorithms, ANODE 2023 -- In honour of John Butcherâ€™s 90th birthday (2024).

1. **A unified discretization framework for differential equation approach with Lyapunov arguments for convex optimization**<br>
   [[arXiv](https://doi.org/10.48550/arXiv.2302.07404)][[proceeding](https://openreview.net/forum?id=8YN62t19AW)]<br>
   K. Ushiyama, S. Sato, T. Matsuo, NeurIPS 2023.

1. **Essential convergence rate of ordinary differential equations appearing in optimization**<br>
   [[arXiv](https://doi.org/10.48550/arXiv.2206.02599)][[journal](https://doi.org/10.14495/jsiaml.14.119)]<br>
   K. Ushiyama, S. Sato, T. Matsuo, JSIAM Letters, **14**(2022), 119--122.<br>

2. **Deriving efficient optimization methods based on stable explicit numerical methods**<br>
   [[journal](https://doi.org/10.14495/jsiaml.14.29)]<br>
   K. Ushiyama, S. Sato, T. Matsuo, JSIAM Letters, **14**(2022), 29--32.

# Talks

1. **Convergence of optimisation methods and stability of numerical methods**<br>
   <u>Kansei Ushiyama</u>, Toshiki Saegusa, Shun Sato, Takayasu Matsuo, Auckland Numerical Analysis WoRKshop,
   Auckland (New Zealand), March 25--29, 2024.

1. **Extending discrete gradients for unified description and analysis of optimization methods**<br>
   <u>K. Ushiyama</u>, S. Sato, T. Matsuo, ANODE 2023, Auckland (New Zealand), February 20--24, 2023.

# Awards

**Dec. 2023**<br>
   Student Excellent Presentation Award, The 26th Information-based Induction Sciences Workshop

**Jul. 2023**<br>
	Best Paper Award in JSIAM Letters, Japan Society for Industrial and Applied Mathematics

**Mar. 2023**<br>
        Dean's award from Graduate School of Information Science and Technology, The University of Tokyo

**Jun. 2022**<br>
        Best Presentation Award, Japan Society for Industrial and Applied Mathematics

# Fellowships
**April 2024 -- March 2026**<br>
   JSPS Research Fellowship for Young Scientists, DC2

**April 2023 -- March 2026**<br>
   JST Support for Pioneering Research Initiated by the Next Generation (SPRING) Program, The University of Tokyo "Advanced Human Resource Development Leading Green Transformation (GX) (SPRING GX)" Project student
