---
# Feel free to add content and custom Front Matter to this file.
# To modify the layout, see https://jekyllrb.com/docs/themes/#overriding-theme-defaults

layout: default
lang: jp
title: Home
---
### \[[English](https://kanseiushiyama.github.io/indexen.html)\]

# 牛山寛生

東京大学大学院情報理工学系研究科<br>
数理情報学専攻 [第3研究室](http://www.sr3.t.u-tokyo.ac.jp/ja/) 博士課程2年<br>
Email: ushiyama-kansei074 (at) g.ecc.u-tokyo.ac.jp

# 研究分野

- 数値解析
- 連続最適化

# 学歴
**2023年3月**<br>
東京大学大学院 情報理工学系研究科 数理情報学専攻 修了<br>
（指導教員：松尾 宇泰 教授）<br>
修士論文：Exploiting Numerical Analytical Concepts for Continuous Optimization:
Numerical Stability and Discrete Chain Rule（連続最適化のための数値解析学諸概念の活用：数値的安定性と離散連鎖律）<br>

**2021年3月**<br>
東京大学 工学部 計数工学科 卒業<br>
（指導教員：泉田 勇輝 講師）<br>
卒業論文：結合振動子系における無相関ノイズによる同期促進のメカニズムの研究

**2017年3月**<br>
長野県長野高等学校 卒業

# プレプリント

1. **Deriving Optimal Rates of Continuous-time Accelerated First-order Methods via Performance Estimation Problems**<br>
   [[METR](https://www.keisu.t.u-tokyo.ac.jp/data/2024/METR24-02.pdf)]<br>
   K. Ushiyama, S. Sato, T. Matsuo, preprint.

# 査読付き論文誌・会議録

1. **Differentiable Pareto-Smoothed Weighting for High-Dimensional Heterogeneous Treatment Effect Estimation**<br>
   [[proceeding](https://openreview.net/forum?id=o85WSGg0oB)]<br>
   Y. Chikahara, K. Ushiyama, UAI 2024.

1. **Analysis of continuous dynamical system models with Hessians derived from optimization methods**<br>
   [[journal](https://doi.org/10.14495/jsiaml.16.29)]<br>
   T. Kamijima, S. Sato, K. Ushiyama, T. Matsuo, K. Tanaka, JSIAM Letters, **16**(2024), 29--32.

1. **Properties and practicability of convergence-guaranteed optimization methods derived from weak discrete gradients**<br>
   [[journal](https://doi.org/10.1007/s11075-024-01790-3)]<br>
   K. Ushiyama, S. Sato, T. Matsuo, Numer. Algorithms, **96**(2024), 1331-–1362.

1. **A unified discretization framework for differential equation approach with Lyapunov arguments for convex optimization**<br>
   [[arXiv](https://doi.org/10.48550/arXiv.2302.07404)][[proceeding](https://openreview.net/forum?id=8YN62t19AW)]<br>
   K. Ushiyama, S. Sato, T. Matsuo, NeurIPS 2023.

1. **Essential convergence rate of ordinary differential equations appearing in optimization**<br>
   [[arXiv](https://doi.org/10.48550/arXiv.2206.02599)][[journal](https://doi.org/10.14495/jsiaml.14.119)]<br>
   K. Ushiyama, S. Sato, T. Matsuo, JSIAM Letters, **14**(2022), 119--122.

1. **Deriving efficient optimization methods based on stable explicit numerical methods**<br>
   [[journal](https://doi.org/10.14495/jsiaml.14.29)]<br>
   K. Ushiyama, S. Sato, T. Matsuo, JSIAM Letters, **14**(2022), 29--32.

# 講演

1. **Performance estimation problems for convergence rate analysis of continuous-time models for optimization algorithms**<br>
   <u>K. Ushiyama</u>, S. Sato, T. Matsuo, Synergies of Machine Learning and Numerics,
   Osaka (Japan), March 11--13, 2025.


1. **非凸最適化の連続時間アルゴリズムと速度制御による離散化**<br>
   <u>牛山 寛生</u>, 佐藤 峻, 日本オペレーションズ・リサーチ学会 2025年春季研究発表会, 東京, March 5--7, 2025.

1. **最適化手法の連続時間モデルに関する本質的な収束率の精緻化**<br>
   <u>牛山 寛生</u>, 佐藤 峻, 松尾 宇泰, 日本応用数理学会 2024年度 年会, 京都, September 14--16, 2024.

1. **非平滑強凸関数最小化問題に対する現状最速の加速近接勾配法**<br>
   <u>牛山 寛生</u>, 日本オペレーションズ・リサーチ学会 2024年秋季研究発表会, 愛知, September 9--11, 2024.<br>
   [予稿中アルゴリズムの修正版](https://kanseiushiyama.github.io/assets/OR2024a.pdf)

1. **Convergence of optimisation methods and stability of numerical methods**<br>
   <u>K. Ushiyama</u>, T. Saegusa, S. Sato, T. Matsuo, Auckland Numerical Analysis WoRKshop,
   Auckland (New Zealand), March 25--29, 2024.

1. **最適化手法の連続時間モデルに対する新しい収束率解析法**<br>
   <u>牛山 寛生</u>, 佐藤 峻, 松尾 宇泰, 日本応用数理学会 第20回研究部会連合発表会, 新潟, March 4–-6, 2024．

1. **A Unified Discretization Framework for Differential Equation Approach with Lyapunov Arguments for Convex Optimization** (poster)<br>
   <u>牛山 寛生</u>, 佐藤 峻, 松尾 宇泰, 第26回情報論的学習理論ワークショップ, 福岡, October 29--November 1, 2023.

1. **最適化のためのRunge--Kutta--Chebyshev法における曲線探索法**<br>
   <u>牛山 寛生</u>, 佐藤 峻, 松尾 宇泰, 数値解析シンポジウム 2023, 岩手, July 12--14, 2023.

1. **最適化手法由来のヘッセ行列を伴う連続力学系モデルに対する数値解析学的アプローチ**<br>
   <u>上島 智哉</u>, 佐藤 峻, 牛山 寛生, 松尾 宇泰, 田中 健一郎, 日本応用数理学会 第19回研究部会連合発表会, 岡山, March 8--10, 2023.

1. **Extending discrete gradients for unified description and analysis of optimization methods**<br>
   <u>K. Ushiyama</u>, S. Sato, T. Matsuo, ANODE 2023, Auckland (New Zealand), February 20--24, 2023.

1. **最適化手法記述のための弱い離散勾配について**<br>
   <u>牛山 寛生</u>, 佐藤 峻, 松尾 宇泰, 2022年度応用数学合同研究集会, 滋賀, December 15--17, 2022.

1. **勾配流に対する離散勾配を用いた最適化手法の統一的記述について**<br>
   <u>牛山 寛生</u>, 佐藤 峻, 松尾 宇泰, 日本応用数理学会 2022年度 年会, 北海道, September 8--10, 2022.

1. **最適化に現れる常微分方程式の本質的収束レート**<br>
   <u>牛山 寛生</u>, 佐藤 峻, 松尾 宇泰, 日本応用数理学会 2021年度 年会, オンライン, September 7--9, 2021.

1. **最適化に適した安定な数値解法について**<br>
   <u>牛山 寛生</u>, 佐藤 峻, 松尾 宇泰, 日本応用数理学会 2021年度 年会, オンライン, September 7--9, 2021.

# 受賞
**2025年3月**<br>
   日本オペレーションズ・リサーチ学会 2025年春季研究発表会 学生優秀発表賞

**2024年10月**<br>
   日本オペレーションズ・リサーチ学会 2024年秋季研究発表会 学生優秀発表賞

**2023年12月**<br>
    第26回情報論的学習理論ワークショップ 学生優秀プレゼンテーション賞

**2023年7月**<br>
    日本応用数理学会 2023年度 JSIAM Letters 論文賞

**2023年3月**<br>
    東京大学大学院情報理工学系研究科長賞

**2022年6月**<br>
    日本応用数理学会 第18回 若手優秀講演賞

# フェローシップ

**2024年4月--2026年3月**<br>
   日本学術振興会特別研究員 DC2

**2023年4月--2026年3月**<br>
   JST次世代研究者挑戦的研究プログラム（SPRING） 東京大学「グリーントランスフォーメーション（ＧＸ）を先導する高度人材育成（SPRING GX）」プロジェクト生
